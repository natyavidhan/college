## 1.1 What Is AI?

### Acting Humanly: The Turing Test Approach

The Turing test, proposed by Alan Turing (1950), was designed as a thought experiment to sidestep the philosophical vagueness of the question, "Can a machine think?". A computer passes the test if a human interrogator, posing written questions, cannot tell whether the written responses come from a person or from a computer.

To pass a rigorously applied Turing test, a computer would need the following capabilities:

- **Natural Language Processing (NLP):** Required for the machine to communicate successfully in a human language.
- **Knowledge Representation (KR):** Needed to store what the system knows or hears.
- **Automated Reasoning (AR):** Necessary to answer questions posed during the test and to draw new conclusions.
- **Machine Learning (ML):** Required for the system to adapt to new circumstances and to detect and extrapolate patterns.

**Total Turing Test** While Turing primarily viewed written communication as sufficient to demonstrate intelligence, other researchers have proposed a **total Turing test**. This variant requires the agent to interact with objects and people in the real world.

To pass the total Turing test, the machine would additionally need:

- **Computer Vision and Speech Recognition:** Required to perceive the real world.
- **Robotics:** Required to manipulate objects and move about.

Despite the importance of the Turing test as a measure of intelligent behavior, AI researchers generally devote little effort to passing it, believing it is more critical to study the underlying principles of intelligence (similar to aeronautical engineers studying aerodynamics instead of strictly imitating birds). To date, no one has developed a system able to pass the Turing test.

### Acting Rationally: The Rational Agent Approach

The alternative approach to defining AI focuses on **rationality**, or abstractly, doing the "right thing". An **agent** is defined simply as something that acts.

A **rational agent** is one that acts so as to achieve the best outcome or, when facing uncertainty, the best expected outcome. All the skills necessary for the Turing test—knowledge representation, reasoning, learning, and natural language generation—are also utilized by an agent striving to act rationally.

The rational-agent approach has two main advantages over other approaches:

1. It is **more general** than the "laws of thought" approach (which focuses only on correct inference), as correct inference is just one mechanism for achieving rationality.
2. It is **more amenable to scientific development** because the standard of rationality is mathematically well defined and completely general.

AI has historically focused on the study and construction of agents that **do the right thing**.

**The Standard Model** The prevalent paradigm in AI is the **standard model**, where rational agents are built on the assumption that they will pursue a fixed, fully specified objective supplied by the human designers, often by maximizing the expected utility.

This model prevails across various fields:

- In **control theory**, a controller minimizes a cost function.
- In **operations research**, a policy maximizes a sum of rewards.
- In **statistics**, a decision rule minimizes a loss function.
- In **economics**, a decision maker maximizes utility.

A necessary refinement to the standard model accounts for the fact that _perfect rationality_—always choosing the exactly optimal action—is often unachievable in complex environments due to the high computational demands, leading to the concept of **limited rationality**. Furthermore, in real-world scenarios, it becomes increasingly difficult to specify the objective completely and correctly, potentially leading to unintended consequences (e.g., in a self-driving car, maximizing "safety" strictly might result in the car never leaving the garage, conflicting with the goal of making progress toward a destination).

## 1.4 The State of the Art

The field of AI is rapidly advancing, with growth tracked by studies like Stanford University’s One Hundred Year Study on AI (AI100) and its AI Index.

**Growth and Activity:**

- **Publications:** The number of AI papers increased 20-fold between 2010 and 2019, reaching about 20,000 per year, with machine learning being the most popular category.
- **Education:** Course enrollment increased 5-fold in the U.S. and 16-fold internationally since 2010. AI is the most popular specialization within Computer Science.
- **Industry:** AI startups in the U.S. increased 20-fold, exceeding 800.
- **Computing Power:** The amount of computing power used in top AI applications is currently doubling approximately every 3.4 months.

**Current Performance and Applications:**

AI systems have achieved or exceeded human-level performance in a wide variety of tasks by 2019.

- **Robotic Vehicles (Autonomous Driving):** The development of self-driving cars accelerated after 2007. In 2018, Waymo test vehicles achieved 10 million miles driven on public roads, requiring human takeover only once every 6,000 miles, and soon began offering commercial robotic taxi service.
- **Speech Recognition and NLP:**
    - In 2017, Microsoft demonstrated a Conversational Speech Recognition System that matched human performance on the Switchboard task, achieving a 5.1% word error rate.
    - Accuracy on question answering tasks (SQUAD) increased from 60 to 95 between 2015 and 2019, surpassing human-level performance.
    - Services like Skype provide real-time speech-to-speech translation in ten languages, and assistants like Alexa, Siri, and Google offer question-answering capabilities.
- **Image Understanding (Computer Vision):**
    - Error rates for object detection in the Large-Scale Visual Recognition Challenge (LSVRC) improved dramatically, exceeding human performance (dropping from 28% in 2010 to 2% in 2017).
    - Vision researchers have tackled complex tasks like image captioning, producing impressive descriptions such as "A person riding a motorcycle on a dirt road".
- **Games:**
    - AI systems have reached or exceeded human-level performance in complex strategy games, including chess, Go, poker, StarCraft II, and Dota 2.
    - **ALPHAZERO**, a followup program, used no human input (except for the rules) and learned through self-play to defeat all top human and machine opponents in Go, chess, and shogi.
    - AI also won the Jeopardy! quiz game championship in 2011.
- **Medicine:**
    - AI algorithms are now equivalent to or better than expert doctors in diagnosing many conditions, particularly those based on image analysis.
    - Examples include diagnosing Alzheimer’s disease, metastatic cancer, ophthalmic disease, and skin diseases.
    - The LYNA system achieved 99.6% overall accuracy in diagnosing metastatic breast cancer; the combined performance of the AI and a human expert was even better than the unaided expert.
- **Climate Science:** Deep learning models have been used to analyze climate data to discover detailed information about extreme weather events, using specialized GPU hardware to exceed the exaop level (10¹⁸ operations per second).